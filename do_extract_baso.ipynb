{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Import libraries\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "from torch import backends\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "##SETTINGS\n",
    "doExtractBaso = True\n",
    "\n",
    "nfold = 10 # Number of folds \n",
    "fold_offset = 1 # Starts from fold 'fold_offset'\n",
    "lr=0.01 #learning rate\n",
    "\n",
    "batch_size = 32\n",
    "val_split = 0.2 #trainset percentage allocated for devset\n",
    "test_val_split = 0.1 #trainset percentage allocated for test_val set (i.e. the test set of known patients)\n",
    "\n",
    "#cwd = os.getcwd()\n",
    "cwd = \"../subjects_intra/min-max/windows_20/tr-False/folds_intra/\"\n",
    "subject = 2 # serve per caricare le folds da cartelle diverse\n",
    "prefix_train = 'TrainFold'\n",
    "prefix_test = 'TestFold'\n",
    "\n",
    "spw=20 #samples per window\n",
    "nmuscles=10 #initial number of muscles acquired\n",
    "\n",
    "\n",
    "\n",
    "# Modelli del paper: 11 (FF2), 14 (FF4), 16 (FF5) --> Prova questi!\n",
    "# FF6 per testarlo potente dopo (17)\n",
    "model_lst = ['FF','FC2','FC2DP','FC3','FC3dp','Conv1d','MultiConv1d',\n",
    "             'MultiConv1d_2','MultiConv1d_3', 'MultiConv1d_4', 'MultiConv1d_5', \n",
    "             'FF2', 'CNN1', 'FF3', 'FF4', 'CNN2', 'FF5', 'FF6', 'CNN3', 'CNN1-FF5', 'CNN1-2','CNN1-1', 'CNN1-3', 'CNN_w60']\n",
    "model_select = [17] \n",
    "\n",
    "#Early stop settings\n",
    "maxepoch = 100\n",
    "maxpatience = 10\n",
    "\n",
    "use_cuda = False\n",
    "use_gputil = False\n",
    "cuda_device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## -- SUBJECT 25 -- #\n",
      "\n",
      "Fold 1: cutting point at window [1356] -- Sample # 1--27120 in the original signal\n",
      "Fold 2: cutting point at window [2712] -- Sample # 27121--54240 in the original signal\n",
      "Fold 3: cutting point at window [4068] -- Sample # 54241--81360 in the original signal\n",
      "Fold 4: cutting point at window [5424] -- Sample # 81361--108480 in the original signal\n",
      "Fold 5: cutting point at window [6780] -- Sample # 108481--135600 in the original signal\n",
      "Fold 6: cutting point at window [8136] -- Sample # 135601--162720 in the original signal\n",
      "Fold 7: cutting point at window [9492] -- Sample # 162721--189840 in the original signal\n",
      "Fold 8: cutting point at window [10848] -- Sample # 189841--216960 in the original signal\n",
      "Fold 9: cutting point at window [12204] -- Sample # 216961--244080 in the original signal\n",
      "Fold 10: cutting point at window [13560] -- Sample # 244081--271200 in the original signal\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '../subjects_intra/min-max/windows_20/tr-False/folds_intra/subject25/cutting_points.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-150-900f1d2d5ba3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcutting_samples_start\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcutting_samples_end\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[0maa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[0maa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../subjects_intra/min-max/windows_20/tr-False/folds_intra/subject'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubject_select\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/cutting_points.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nThe number of column for each window is \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   3226\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3227\u001b[0m         )\n\u001b[1;32m-> 3228\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3230\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    181\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m                 \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m             )\n\u001b[0;32m    185\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    397\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    400\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m             \u001b[1;31m# No explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '../subjects_intra/min-max/windows_20/tr-False/folds_intra/subject25/cutting_points.csv'"
     ]
    }
   ],
   "source": [
    "## -- Load Folds\n",
    "## -- This script loads in memory the ten folds (UNLEARNED) previously created\n",
    "## -- To be further predicted by the ANN and then reconstructed\n",
    "\n",
    "subject_select = 25\n",
    "nfold = 10\n",
    "fold_offset = 1\n",
    "window_length = 20\n",
    "\n",
    "prefix_test = 'subject' + str(subject_select) + '/TestFold'\n",
    "prefix_cut = 'subject' + str(subject_select) + '/s'\n",
    "\n",
    "# This variable will contain the unlearned piece of signal for each fold\n",
    "testfolds = []\n",
    "\n",
    "cuts = pd.read_csv(os.path.join(cwd, prefix_cut + str(subject_select) + '_fold_log.csv'), header = None)\n",
    "cutting_points = cuts.to_numpy()\n",
    "pace = int(cutting_points[1] - cutting_points[0])\n",
    "\n",
    "cutting_samples_start = []\n",
    "cutting_samples_end = []\n",
    "\n",
    "print(\"## -- SUBJECT \" + str(subject_select) + \" -- #\\n\")\n",
    "for j in range(fold_offset,fold_offset + nfold):\n",
    "    testdata = pd.read_csv(os.path.join(cwd, prefix_test + str(j) + '.csv'),sep=',',header=None, dtype=np.float32)\n",
    "    testfolds.append(testdata)\n",
    "    print(\"Fold \" + str(j) + \": cutting point at window \" + str(cutting_points[j-1]) + \" -- Sample # \" + str(abs(int(20*pace - 20*cutting_points[j-1])) + 1) + \"--\" + str(int(20*cutting_points[j-1])) + \" in the original signal\")\n",
    "    \n",
    "    # Salvo i cutting points\n",
    "    cutting_samples_start.append(abs(int(20*pace - 20*cutting_points[j-1])) + 1)\n",
    "    cutting_samples_end.append(int(20*cutting_points[j-1]))\n",
    "n_muscles=int((len(testdata.columns)-1)/window_length) \n",
    "\n",
    "## -- Salvo i cutting points su un file\n",
    "a = list(zip(cutting_samples_start,cutting_samples_end))\n",
    "aa = pd.DataFrame(a)\n",
    "aa = aa.to_csv('../subjects_intra/min-max/windows_20/tr-False/folds_intra/subject' + str(subject_select) + '/cutting_points.csv', index = None, header = None)\n",
    "\n",
    "print(\"\\nThe number of column for each window is \" + str(len(testdata.columns)))\n",
    "print(\"The number of muscles is \" + str(n_muscles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## -- Salva il basografico predetto su un file sfruttando l'accuracy\n",
    "\n",
    "def save_predicted_baso(loader, model, subject_select, model_select, num_fold):\n",
    "    windows_length = 20\n",
    "    predicted_baso_windowed = []\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        ## -- Estrae gli output di ciascuna window\n",
    "        for i, data, in enumerate(loader, 0):\n",
    "            inputs, labels = data\n",
    "            outputs = model(inputs)\n",
    "            outputs[outputs >= 0.5] = 1\n",
    "            outputs[outputs < 0.5] = 0\n",
    "            predicted_temp = outputs.tolist()\n",
    "            predicted_baso_windowed.extend(predicted_temp)\n",
    "        \n",
    "        predicted_baso_windowed = pd.DataFrame(predicted_baso_windowed)    # Converto in DataFrame\n",
    "        predicted_baso_windowed = predicted_baso_windowed.as_matrix()\n",
    "        \n",
    "        limit = len(predicted_baso_windowed)\n",
    "        predicted_baso = np.empty([limit*windows_length,1], dtype = int)\n",
    "        \n",
    "        count = 0\n",
    "        for j in range(0, limit):\n",
    "            predicted_baso[count:count+windows_length] = predicted_baso_windowed[j]\n",
    "            count += windows_length\n",
    "            \n",
    "        predicted_baso = pd.DataFrame(predicted_baso)\n",
    "        out_path = '../subjects_intra/min-max/windows_20/tr-False/folds_intra/subject' + str(subject_select) + \"/Predicted/\"  \n",
    "        if not os.path.exists(out_path):\n",
    "            os.makedirs(out_path)\n",
    "        predicted_baso = predicted_baso.to_csv(out_path + str(num_fold) + '_predicted.csv', index = None, header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import models\n",
    "from models import *\n",
    "models._spw = spw\n",
    "models._nmuscles = nmuscles\n",
    "models._batch_size = batch_size\n",
    "\n",
    "#Seeds\n",
    "def setSeeds(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "setSeeds(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def train_test():\n",
    "    print('Model ' + str(model_select) + ' - Subject ' + str(subject_select) + '\\n')\n",
    "    for k in model_select:\n",
    "            for i in range(1,nfold+1):\n",
    "                \n",
    "               # t0 = time.time()\n",
    "                setSeeds(0)\n",
    "                \n",
    "                # Classe per il Testset UNLEARNED\n",
    "                class Testdataset_U(Dataset):\n",
    "                    def __init__(self):\n",
    "                        self.data=testfolds[i-1]\n",
    "                        self.x_data=torch.from_numpy(np.asarray(self.data.iloc[:, 0:-1]))\n",
    "                        self.len=self.data.shape[0]\n",
    "                        self.y_data = torch.from_numpy(np.asarray(self.data.iloc[:, [-1]]))\n",
    "                        if (use_cuda):\n",
    "                            self.x_data = self.x_data.cuda()\n",
    "                            self.y_data = self.y_data.cuda()\n",
    "                    def __getitem__(self, index):\n",
    "                        return self.x_data[index], self.y_data[index]\n",
    "                    def __len__(self):\n",
    "                        return self.len\n",
    "\n",
    "                ## DEFINISCO I DATASET DA CARICARE    \n",
    "                testdataset_U = Testdataset_U()    # Test dataset UNLEARNED\n",
    "                test_loader = torch.utils.data.DataLoader(testdataset_U, batch_size = batch_size, \n",
    "                                                          drop_last = True)\n",
    "                #print('Test Set (U) dimension: ' + str(len(test_loader)))\n",
    "                \n",
    "                modelClass = \"Model\" + str(k)\n",
    "                model = eval(modelClass)()\n",
    "                \n",
    "                if (use_cuda):\n",
    "                    model = model.cuda()\n",
    "                \n",
    "                fold_predicted = i\n",
    "                model_folder = \"../subjects_intra/min-max/windows_20/tr-False/folds_intra/subject\" + str(subject_select) + \"/Report_FF6/\"\n",
    "                \n",
    "                if doExtractBaso:\n",
    "                    if use_cuda:                        \n",
    "                        state = torch.load(os.path.join(model_folder,'F'+str(i)+'best.pth.tar'))\n",
    "                    else:\n",
    "                        state = torch.load(os.path.join(model_folder,'F'+str(i)+'best.pth.tar'), map_location=lambda storage, loc: storage)\n",
    "                    stop_epoch = state['epoch']\n",
    "                    model.load_state_dict(state['state_dict'])\n",
    "                    if not use_cuda:\n",
    "                        model.cpu()\n",
    "                    accuracy_dev = state['best_acc_dev']\n",
    "                    model.eval()\n",
    "                    \n",
    "                    ## -- QUESTO DEVI CONTROLLARLO! SE ESCE CHE i Ãˆ DIVERSO DALLA FOLD DEVI RIFARE TUTTO!\n",
    "                    \n",
    "                    print('F' + str(i) + 'best.pth.tar')\n",
    "                    predicted_baso = save_predicted_baso(test_loader, model, subject_select, model_lst[k], fold_predicted)   \n",
    "            \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am NOT using CUDA: SUCCESS!\n",
      "Model [17] - Subject 24\n",
      "\n",
      "F1best.pth.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nabuconodosor II\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:18: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F2best.pth.tar\n",
      "F3best.pth.tar\n",
      "F4best.pth.tar\n",
      "F5best.pth.tar\n",
      "F6best.pth.tar\n",
      "F7best.pth.tar\n",
      "F8best.pth.tar\n",
      "F9best.pth.tar\n",
      "F10best.pth.tar\n"
     ]
    }
   ],
   "source": [
    "#nmuscles=int((len(traindata.columns)-1)/spw)\n",
    "if use_cuda and not use_gputil and cuda_device!=None and torch.cuda.is_available():\n",
    "    with torch.cuda.device(cuda_device):\n",
    "        print('I am using CUDA: SUCCESS!')\n",
    "        train_test()\n",
    "else:\n",
    "    print('I am NOT using CUDA: SUCCESS!')\n",
    "    train_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
